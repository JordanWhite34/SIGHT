{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jordanwhite/Projects/yolov8/yolo-v8/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m venv env\n",
    "!pip install ultralytics\n",
    "!pip install clearml\n",
    "!pip install split-folders\n",
    "!pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import splitfolders\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"archive/images\" # The path to the folder with images.\n",
    "TARGET_PATH = \"archive/annotation/annotation\" # The path to the folder with the annotation (labels). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_path: str, target_path: str) -> pd.DataFrame:\n",
    "    assert isinstance(data_path, str) \n",
    "    assert isinstance(target_path, str)\n",
    "    \n",
    "    dict_paths = {\n",
    "        \"image\": [],\n",
    "        \"annotation\": []\n",
    "    }\n",
    "    \n",
    "    for dir_name, _, filenames in os.walk(data_path):\n",
    "        for filename in tqdm(filenames):\n",
    "            name = filename.split('.')[0]\n",
    "            dict_paths[\"image\"].append(f\"{data_path}/{name}.jpg\")\n",
    "            dict_paths[\"annotation\"].append(f\"{target_path}/{name}.txt\")\n",
    "\n",
    "    \n",
    "    dataframe = pd.DataFrame(\n",
    "        data=dict_paths,\n",
    "        index=np.arange(0, len(dict_paths[\"image\"]))\n",
    "    )\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dirs(dataset_path: str,\n",
    "                 annotation_path: str,\n",
    "                 images_path: str) -> None:\n",
    "    if not os.path.exists(dataset_path):\n",
    "        os.mkdir(path=dataset_path)\n",
    "        os.mkdir(path=annotation_path)\n",
    "        os.mkdir(path=images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dirs(dataframe: pd.DataFrame, \n",
    "             data_path: str,\n",
    "             target_path: str) -> None:\n",
    "    \n",
    "    assert isinstance(dataframe, pd.DataFrame)\n",
    "    assert isinstance(data_path, str) \n",
    "    assert isinstance(target_path, str)\n",
    "    \n",
    "    for i in tqdm(range(len(dataframe))):\n",
    "        image_path, annotation_path = dataframe.iloc[i]\n",
    "        shutil.copy(image_path, data_path)\n",
    "        shutil.copy(annotation_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalizing_preparation(dataset_path: str, ladd_path: str):\n",
    "    assert os.path.exists(f\"{dataset_path}\")\n",
    "    \n",
    "    example_structure = [\n",
    "        \"dataset\", \n",
    "        \"train\", \"labels\", \"images\",\n",
    "        \"test\",\"labels\", \"images\",\n",
    "        \"val\", \"labels\", \"images\"\n",
    "    ]\n",
    "    \n",
    "    dir_bone = (\n",
    "        dirname.split(\"/\")[-1]\n",
    "        for dirname, _, filenames in os.walk('/kaggle/working/dataset')\n",
    "        if dirname.split(\"/\")[-1] in example_structure\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"\\n~ Lacmus Dataset Structure ~\\n\")\n",
    "        print(\n",
    "        f\"\"\"\n",
    "      ├── {next(dir_bone)}\n",
    "      │   │\n",
    "      │   ├── {next(dir_bone)}\n",
    "      │   │   └── {next(dir_bone)}\n",
    "      │   │   └── {next(dir_bone)}\n",
    "      │   │        \n",
    "      │   ├── {next(dir_bone)}\n",
    "      │   │   └── {next(dir_bone)}\n",
    "      │   │   └── {next(dir_bone)}\n",
    "      │   │\n",
    "      │   ├── {next(dir_bone)}\n",
    "      │   │   └── {next(dir_bone)}\n",
    "      │   │   └── {next(dir_bone)}\n",
    "        \"\"\"\n",
    "        )\n",
    "    except StopIteration as e:\n",
    "        print(e)\n",
    "    else:\n",
    "        print(Fore.GREEN + \"-> Success\")\n",
    "    finally:\n",
    "        os.system(f\"rm -rf {ladd_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataset(\n",
    "    data_path=IMAGE_PATH,\n",
    "    target_path=TARGET_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"working/dataset\"\n",
    "ladd_path = \"working/ladd\"\n",
    "annotation_path = \"working/ladd/labels\"\n",
    "image_path = \"working/ladd/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dirs(\n",
    "    dataset_path=ladd_path,\n",
    "    annotation_path=annotation_path,\n",
    "    images_path=image_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "copy_dirs(\n",
    "    dataframe=df, \n",
    "    data_path=image_path,\n",
    "    target_path=annotation_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(ladd_path, exist_ok=True)\n",
    "os.makedirs(annotation_path, exist_ok=True)\n",
    "os.makedirs(image_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2730 files [00:00, 14840.84 files/s]\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio(\n",
    "    input=ladd_path,\n",
    "    output=dataset_path,\n",
    "    seed=42,\n",
    "    ratio=(0.80, 0.10, 0.10),\n",
    "    group_prefix=None,\n",
    "    move=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~ Lacmus Dataset Structure ~\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalizing_preparation(\n",
    "    dataset_path,\n",
    "    ladd_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-v8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
